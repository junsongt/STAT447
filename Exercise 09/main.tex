% Template for solutions write-ups, STAT 460/560
% Some basic notation is defined in 'macros/basic-math-macros'

\documentclass{article}
\input{macros/solutions-template}  % DO NOT CHANGE
\input{macros/typesetting-macros}  % DO NOT CHANGE
\input{macros/basic-math-macros} 
\graphicspath{{./figures/}}







\begin{document}



% FILL IN:
%  - YOUR NAME, YOUR EMAIL (self-explanatory)
%  - The assignment number goes in ##
\problemset{Junsong Tang}{junsong.tang@stat.ubc.ca}{Exercise 9}



% WRITE YOUR SOLUTION TO THE FIRST QUESTION
\qsol{A custom MCMC sampler}
\begin{enumerate}
\item 
Let $K(\mu_1', \mu_2', c' | \mu_1, \mu_2, c)$ be the MCMC kernel. Define $K$ to be:
\[K(\mu_1', \mu_2', c' | \mu_1, \mu_2, c) = K_1(\mu_1', \mu_2', c | \mu_1, \mu_2, c) + \frac12 K_2(\mu_1, \mu_2, c' | \mu_1, \mu_2, c)\]where $K_1, K_2$ are MCMC kernels corresponding to the update of $(\mu_1, \mu_2)$ and $c$. So then the MCMC algorithm is:
\begin{algorithm}
    \caption{custom MCMC}
    \label{algo:mixture}
    \begin{algorithmic}[1]
        \Require $\mu_1, \mu_2, c, y, N$
        \Ensure $\{c_1, \ldots, c_N\}$ and $(\mu_1^{(N)}, \mu_2^{(N)})$

        \For{$j = 1, \ldots, N$}
        \State sample $i \sim \Bernoulli(\frac12)$
        \If{$i = 1$}
        \State sample $c' \sim q_c( \cdot | c)$
        \State $r = \exp(log\pi(\mu_1, \mu_2, c') - \log\pi(\mu_1, \mu_2, c))$
        \State $c_j = \Unif(0,1) < (1 \wedge r) ? c' : c$

        \Else 
        \State sample $\mu_1' \sim q_{\mu_1}(\cdot | \mu_1)$ and $\mu_2' \sim q_{\mu_2}(\cdot | \mu_2)$
        \State $r = \exp(log\pi(\mu_1', \mu_2', c) - \log\pi(\mu_1, \mu_2, c))$
        \State $(\mu_1, \mu_2) = \Unif(0,1) < (1 \wedge r) ? (\mu_1', \mu_2') : (\mu_1, \mu_2)$

        \EndIf
        \EndFor
    \end{algorithmic}

\end{algorithm}



\item 
\begin{lstlisting}[language=R]
mcmc = function(means, change_point, y, n_iterations) {
    change_point_trace = rep(-1, n_iterations)
    for (i in 1:n_iterations) {
        # K2 for c
        proposed_c = floor(rnorm(1, change_point, sd) + 0.5) # discrete normal proposal
        # proposed_c = rnorm(1, change_point, sd = sd)
        # proposed_c = ifelse(proposed_c >= change_point, ceiling(proposed_c), floor(proposed_c)) # proposal
        ratio = exp(log_joint(means, proposed_c, y) - log_joint(means, change_point, y)) # M-H ratio
        # n = 2 * change_point
        # proposed_c = rbinom(1, n, 0.5)
        # ratio = exp(log_joint(means, proposed_c, y) - log_joint(means, change_point, y) + dbinom(proposed_c, n, 0.5, log=TRUE) - dbinom(change_point, n, 0.5, log=TRUE)) # M-H ratio
        change_point = ifelse(runif(1) < min(ratio,1), proposed_c, change_point) # acceptance
        change_point_trace[i] = change_point
        # K1 for mu
        proposed_mu = rnorm(2, means, 0.1)
        ratio = exp(log_joint(proposed_mu, change_point, y) - log_joint(means, change_point, y))
        if (runif(1) < min(ratio, 1)) {
        means = proposed_mu
        }
        # means = ifelse(runif(1) < min(ratio,1), proposed_mu, means) # !!! VERY ANNOYING BUG
    }
    
    # Return:
    # - the trace of the change points (for question 1) 
    # - the means at the last iteration (for question 2)
    return(
        list(
        change_point_trace = change_point_trace, 
        last_iteration_means = means 
        )
    )
}
\end{lstlisting}



\end{enumerate}



\qsol{MCMC correctness testing}
\begin{enumerate}
\item 
\begin{lstlisting}[language=R]
forward = function(synthetic_data_size) {
    means = runif(2, 0.1, 0.9)
    change_point = ceiling(runif(1, 0, synthetic_data_size))
    data = numeric(synthetic_data_size)
    for (i in 1:synthetic_data_size) {
        index = ifelse(i >= change_point, 1, 0) + 1
        data[i] = 5 * rbeta(1, means[index]*5, (1-means[index])*5)
    } 
    return(list(
        means = means,
        change_point = change_point,
        data = data
    ))
}
\end{lstlisting}


\item 
\begin{lstlisting}[language=R]
# 2
# Note: we use synthetic datasets with only 5 observations to speed things up
forward_only = replicate(1000, forward_posterior(5, 0))
with_mcmc = replicate(1000, forward_posterior(5, 200))

# TODO: perform 2-samples t-test or Kolmogorov-Smirnov test
#       to see if forward_only and with_mcmc follow the same distribution. 
ks.test(forward_only, with_mcmc)
# p-value = 0.9135
\end{lstlisting}
\end{enumerate}

\qsol{Using your sampler for data analysis}
\begin{enumerate}
\item 
\begin{lstlisting}[language=R]
sd = 6
initial_mu = runif(2, 0.1, 0.9)
initial_c = ceiling(runif(1, 0, length(food_data)))
samples = mcmc(initial_mu, initial_c, food_data, 10000)
plot(samples$change_point_trace)
plot(samples$change_point_trace[5000:10000], axes = TRUE, type = "o", col = rgb(red = 0, green = 0, blue = 0, alpha = 0.2))  
\end{lstlisting}
\begin{figure}
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{}
        \caption{Trace plot of all}
        \label{fig:trace_all}
    \end{minipage}
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{}
        \caption{Trace plot of tail}
        \label{fig:trace_tail}
    \end{minipage}
\end{figure}

\item 
\begin{lstlisting}[language=R]
hist(samples$change_point_trace[5000:10000]) 
\end{lstlisting}
\begin{figure}
\centering
\includegraphics[options]{name}
\caption{Histogram of tail}
\label{fig:hist}
\end{figure}


\end{enumerate}
 
\end{document}

