% Template for solutions write-ups, STAT 460/560
% Some basic notation is defined in 'macros/basic-math-macros'

\documentclass{article}
\input{macros/solutions-template}  % DO NOT CHANGE
\input{macros/typesetting-macros}  % DO NOT CHANGE
\input{macros/basic-math-macros} 
\graphicspath{{./figures/}}







\begin{document}



% FILL IN:
%  - YOUR NAME, YOUR EMAIL (self-explanatory)
%  - The assignment number goes in ##
\problemset{Junsong Tang}{junsong.tang@stat.ubc.ca}{Exercise 2}



% WRITE YOUR SOLUTION TO THE FIRST QUESTION
\qsol{define a Bayesian model} % USE THE SAME TITLES AS ON THE ASSIGNMENT SHEET
\begin{enumerate}
  \item The unknown quantity is the value of $p$, and the data is the observed value of $Y_i$'s.
  \item \begin{align*}
  & X \sim \rho, \rho = (\rho_k)_{k=1}^K\\
  & Y | X \sim \Bernoulli(X)
  \end{align*}
\end{enumerate}

% WRITE YOUR SOLUTION TO THE SECOND QUESTION
\qsol{posterior and point estimates}
\begin{enumerate}
  \item 
  \begin{lstlisting}[language=R]
    prior_probabilities = NULL
    realizations = NULL
    for (k in (0 : K)) {
        prior_probabilities = c(prior_probabilities, (k/K)*(1-k/K))
        realizations = c(realizations, k/K)
    }
    prior_probabilities
    realizations
    plot(realizations, prior_probabilities, type="h", main = "prior pmf")
  \end{lstlisting}
  \includegraphics[width=0.5\textwidth]{prior pmf.png}
  


  \item 
  \begin{lstlisting}[language=R]
    posterior_probabilities = NULL
    Z = 0
    for (k in (0 : K)) {
      # likelihood = P(X = k/K) * P(Y = (1,1,1) | X = k/K)
      likelihood = realizations[k+1]**3 * prior_probabilities[k+1]
      Z = Z + likelihood
      posterior_probabilities = c(posterior_probabilities, likelihood)
    }
    posterior_probabilities = posterior_probabilities / Z
    posterior_probabilities
    plot(realizations, posterior_probabilities, type = "h", main = "posterior pmf")
  \end{lstlisting}
  \includegraphics[width=0.5\textwidth]{posterior pmf.png}
  


  \item From the plot, we can see the posterior mode is at $X = 0.8$
  
  \item 
  \begin{lstlisting}[language=R]
    # posterior mean
    m = 0
    for (k in (0 : K)) {
      x = realizations[k+1]
      pi_k = posterior_probabilities[k+1]
      m = m + x * pi_k
    }
    m #0.712497759455099 
  \end{lstlisting}
\end{enumerate}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\qsol{Bayes action}
\begin{enumerate}
  \item Set the money unit into $\$M$ 
  \begin{align*}
    & L(a, Y_4) = \1_{a = 0} \cdot \$0 + \1_{a = 1; Y_4 = 1} \cdot \$2 + \1_{a = 1; Y_4 = 0} \cdot (\$2 - \$100)\\
    & = 2 \1_{a = 1; Y_4 = 1} - 98 \1_{a = 1; Y_4 = 0}\\
  \end{align*}


  \item By LOTUS,
  \begin{align*}
   & \Lcal(a) = \E[L(a, Y_4) | Y_{1:3} = (1,1,1)]\\
   & = \sum_{y_4 \in \{0,1\}} L(a, Y_4=y_4) \cdot \P(Y_4 = y_4 | Y_{1:3} = (1,1,1))\\
   & = 2\1_{a=1} \cdot \P(Y_4 = 1 | Y_{1:3} = (1,1,1)) - 98 \1_{a=1} \cdot \P(Y_4 = 0 | Y_{1:3} = (1,1,1))\\
   & = 2\1_{a=1}\cdot p - 98\1_{a=1} \cdot (1-p); \text{ where } p := \P(Y_4 = 1 | Y_{1:3} = (1,1,1))\\
  \end{align*}


  \item Plug in the value of $p$ that has been computed in q2(4), then we have $\Lcal(a) = -26.75\1_{a=1}$, so $\Lcal(1) < \Lcal(0)$, meaning we need to buy insurance. 
  
  However, if $\Lcal(0) < \Lcal(1) \Rightarrow (2p-98(1-p)) > 0 \Rightarrow p > 0.98$, then we don't need to buy insurance for the posterior at least $98\%$.
\end{enumerate}


\qsol{Challenges}
\begin{enumerate}

\item
\begin{lstlisting}[language=R]
  # challenge question
  # signature: posteriors, threshold -> index set
  # overall complexity:
  # time: O(nlogn + 2n)
  # space: O(n)
  
  highest_prob_set = function(posterior_probabilities, alpha) {
      n = length(posterior_probabilities)
      # create hashmap that maps prob -> index
      # time complexity O(n) and space complexity O(n)
      dict = c()
      for (i in (1:n)) {
          # set k-v pair as (prob, index)
          p = posterior_probabilities[i]
          dict[as.character(p)] = i
      }
      # sort complexity: O(nlogn)
      posterior_probabilities = sort(posterior_probabilities, decreasing = TRUE)
  
      # linear search complexity: O(n)
      j = 1
      sum = 0
      hps = NULL
      while (j <= n && sum < alpha) {
          p = posterior_probabilities[j]
          hps = c(hps, dict[as.character(p)])
          j = j + 1
          sum = sum + p
      }
  
      return (hps)
  }
\end{lstlisting}


\item 
\begin{lstlisting}[language=R]
  print(highest_prob_set(posterior_probabilities = posterior_probabilities, alpha=0.75))
  # 17, 16, 18, 15, 19, 14, 13, 12
\end{lstlisting}

\end{enumerate}






% Optional: Feedback on assignment
% \qsol{Feedback on assignment}

 
\end{document}

