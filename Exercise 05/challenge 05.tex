% Template for solutions write-ups, STAT 460/560
% Some basic notation is defined in 'macros/basic-math-macros'

\documentclass{article}
\input{macros/solutions-template}  % DO NOT CHANGE
\input{macros/typesetting-macros}  % DO NOT CHANGE
\input{macros/basic-math-macros} 
\graphicspath{{./figures/}}


\DeclareMathOperator{\Cauchy}{Cauchy}




\begin{document}



% FILL IN:
%  - YOUR NAME, YOUR EMAIL (self-explanatory)
%  - The assignment number goes in ##
\problemset{Junsong Tang}{junsong.tang@stat.ubc.ca}{Exercise 5}



% WRITE YOUR SOLUTION TO THE FIRST QUESTION
\qsol{Challenge questions} % USE THE SAME TITLES AS ON THE ASSIGNMENT SHEET
The model can be written as:
\begin{align*}
& C_1 \sim \Cauchy(0,1)\\
& C_2 \sim \Cauchy(0,1)\\
& Y_1|C_1=c_1, C_2=c_2 \sim N(0.1 c_1, 1)\\
& Y_2|C_1=c_1, C_2=c_2 \sim N(-0.3 c_1, 1)\\
& Y_3|C_1=c_1, C_2=c_2 \sim N(0,1)
\end{align*}

\begin{lstlisting}[language=R]
    data {
        matrix[3,2] design_matrix; // number of successes
        vector[3] observations;
    }

    parameters {
    vector[2] coefficients;
    }

    model {
    coefficients[1] ~ cauchy(0, 1);
    coefficients[2] ~ cauchy(0, 1);
    
    for (i in 1:3) {
        observations[i] ~ normal(design_matrix[i] * coefficients, 1);
    }
    }
\end{lstlisting}
\begin{lstlisting}[language=R]
    suppressPackageStartupMessages(require(rstan))
    suppressPackageStartupMessages(require(bayesplot))
    suppressPackageStartupMessages(require(ggplot2))
    matrix = rbind(
        c(0.1, 0),
        c(-0.3, 0),
        c(0, 0)
    )
    obs = c(0.2, 0.1, -0.4)
    fit = sampling(
        cauchy,
        seed = 1,
        refresh = 0,
        data = list(design_matrix = matrix, observations = obs),        
        iter = 10000                   
    )
    mcmc_trace(fit, pars = c("coefficients[1]", "coefficients[2]")) + theme_minimal()
\end{lstlisting}
We implemented the model and generated the trace plot of MCMC samples of $C_1, C_2$ (See Figure \ref{fig:trace}). So from EDA, it can be observed that $C_2$ could go very wildly to extreme range of values.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=0.4\textheight]{trace.png}
    \caption{Trace plots of coefficient $1$ and $2$}
    \label{fig:trace}
\end{figure}
By closer look at the model, we can derive the unnormalized joint posterior density of $C_1, C_2$, which is:
\begin{align}
& \pi(c_1, c_2 | Y = (y_1, y_2, y_3)) \propto \Big(\prod_{i=1}^3 p(y_i |c_1, c_2)\Big) \cdot p(c_1) \cdot p(c_2) \notag\\
& = \exp(-\frac12 (y_1-0.1c_1)^2) \cdot \exp(-\frac12 (y_2+0.3c_1)^2)  \cdot \exp(-\frac12 y_3^2) \cdot \frac{1}{\pi(1+c_1^2)} \cdot \frac{1}{\pi(1+c_2^2)} \notag\\
&\propto \exp\Big(-\frac12 [(y_1-0.1c_1)^2 + (y_2+0.3c_1)^2]\Big) \cdot \frac{1}{(1+c_1^2)} \cdot \frac{1}{(1+c_2^2)} \label{eqn:joint}
\end{align}
Hence we could infer the marginal density of $C_2$ from (\ref{eqn:joint}) by integrating over $c_1$, which is again a Cauchy distribution. But Cauchy random variable is known to have undefined expectation, i.e. $\E C_2 = \infty$, hence it is expected that $C_2$ takes values at extreme range as the phenomenon displayed above.

However, it does not matter whether we use i.i.d. samples of $C_1, C_2$, because MCMC converges to the true posterior as the number of iteration increases. Even if we use i.i.d samples, then $C_2$ should always be expected to touch extreme values.






% Optional: Feedback on assignment
% \qsol{Feedback on assignment}

 
\end{document}

